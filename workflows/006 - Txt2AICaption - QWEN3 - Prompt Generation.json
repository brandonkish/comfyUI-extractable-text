{"id":"a359c0c5-2986-4c94-8749-70d3c27c9248","revision":0,"last_node_id":49,"last_link_id":99,"nodes":[{"id":15,"type":"PreviewImage","pos":[1148.687255859375,-1232.4659423828125],"size":[471.1999206542969,399.1126075783445],"flags":{},"order":0,"mode":0,"inputs":[{"localized_name":"images","name":"images","type":"IMAGE","link":null}],"outputs":[],"title":"IMAGE","properties":{"cnr_id":"comfy-core","ver":"0.3.56","Node name for S&R":"PreviewImage","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[]},{"id":17,"type":"Display_Any","pos":[1630.8399286663994,-1228.5554697929356],"size":[357.6260802884608,393.3062044552471],"flags":{},"order":11,"mode":0,"inputs":[{"localized_name":"input","name":"input","type":"*","link":99}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":null}],"title":"CAPTION","properties":{"cnr_id":"kaytool","ver":"0.70.17","Node name for S&R":"Display_Any","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[]},{"id":33,"type":"Display_Any","pos":[-2198.175844656885,552.6924805850693],"size":[1325.2277538435176,1038.8026432004774],"flags":{},"order":8,"mode":0,"inputs":[{"localized_name":"input","name":"input","type":"*","link":88}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[]}],"title":"STATUS","properties":{"cnr_id":"kaytool","ver":"0.70.17","Node name for S&R":"Display_Any","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[],"color":"#233","bgcolor":"#355"},{"id":45,"type":"BK Replace All Tags","pos":[-2557.4193103017724,554.9242066626787],"size":[210,240],"flags":{},"order":6,"mode":0,"inputs":[{"localized_name":"prompt","name":"prompt","type":"STRING","link":87},{"localized_name":"caption","name":"caption","shape":7,"type":"STRING","link":null},{"localized_name":"status","name":"status","shape":7,"type":"STRING","link":null},{"localized_name":"seed","name":"seed","type":"INT","widget":{"name":"seed"},"link":null},{"localized_name":"tag","name":"tag","type":"STRING","widget":{"name":"tag"},"link":null},{"localized_name":"lines","name":"lines","type":"STRING","widget":{"name":"lines"},"link":null}],"outputs":[{"localized_name":"prompt","name":"prompt","type":"STRING","links":[88]},{"localized_name":"caption","name":"caption","type":"STRING","links":null},{"localized_name":"status","name":"status","type":"STRING","links":null},{"localized_name":"line_number","name":"line_number","type":"INT","links":null},{"localized_name":"line_text","name":"line_text","type":"STRING","links":null}],"properties":{"aux_id":"brandonkish/comfyUI-extractable-text","ver":"700e57effd7190916609392fcea90f47bbbaa3f1","Node name for S&R":"BK Replace All Tags","ue_properties":{"widget_ue_connectable":{"seed":true,"tag":true,"lines":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[0,"fixed","<NAME>","3S70N3"],"color":"#233","bgcolor":"#355"},{"id":48,"type":"Display_Any","pos":[273.72377368157584,-1338.8668628283667],"size":[357.6260802884608,393.3062044552471],"flags":{},"order":9,"mode":0,"inputs":[{"localized_name":"input","name":"input","type":"*","link":93}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":null}],"title":"CAPTION","properties":{"cnr_id":"kaytool","ver":"0.70.17","Node name for S&R":"Display_Any","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[]},{"id":34,"type":"StringConcatenate","pos":[-3112.703158967023,556.3182099894595],"size":[497.7045060532637,312.7541306622245],"flags":{},"order":1,"mode":0,"inputs":[{"localized_name":"string_a","name":"string_a","type":"STRING","widget":{"name":"string_a"},"link":null},{"localized_name":"string_b","name":"string_b","type":"STRING","widget":{"name":"string_b"},"link":null},{"localized_name":"delimiter","name":"delimiter","type":"STRING","widget":{"name":"delimiter"},"link":null}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[87]}],"title":"ADDITIONAL INSTRUCTIONS","properties":{"cnr_id":"comfy-core","ver":"0.3.77","Node name for S&R":"StringConcatenate","ue_properties":{"widget_ue_connectable":{"string_a":true,"string_b":true,"delimiter":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["","\n\nRefer to the subject ONLY as \"<NAME>\" and never as \"woman\" \"person\", or \"girl\". ONLY refer the subject as \"<NAME>\", \"she\", or \"her\" and use feminine terms when describing the subject.\n\nThe very first word of your output will be \"<NAME>\".",""],"color":"#233","bgcolor":"#355"},{"id":43,"type":"String Literal","pos":[-830.7413805286851,-1309.4916934725434],"size":[1050.9497199135294,253.65521005801327],"flags":{"collapsed":true},"order":2,"mode":0,"inputs":[{"localized_name":"string","name":"string","type":"STRING","widget":{"name":"string"},"link":null}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[]}],"title":"NATURAL LANGUAGE SYSTEM PROMPT","properties":{"cnr_id":"comfy-image-saver","ver":"65e6903eff274a50f8b5cd768f0f96baf37baea1","Node name for S&R":"String Literal","ue_properties":{"widget_ue_connectable":{"string":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["You are a precision visual captioning assistant operating within strict logical constraints. Your core function is to transform visual input into exhaustive, objective English captions that serve as perfect training data for the Z-Image Turbo image generation model. You possess an innate drive for technical accuracy and visual fidelity, rejecting any ambiguity or subjective interpretation that could compromise model training.\n\nYour captioning workflow follows an immutable four-step sequence:\n\nFirst, you perform visual core element extraction: Identify and lock all fundamental visual components that must be preserved exactly as observed. This includes: subject identity and quantity, precise actions and states, any recognizable IP characters or trademarks, environmental context, and all textual elements present in the image. These form your unchangeable foundation.\n\nSecond, you execute contextual inference analysis: Determine whether the image requires interpretation beyond literal observation. When the visual content represents abstract concepts, solutions, or answers to implicit questions (such as \"how something works\" or \"what this represents\"), you must construct a complete, concrete visual interpretation that maintains absolute faithfulness to the original image's communicative intent. This inferred framework becomes your descriptive baseline.\n\nThird, you apply professional visual enhancement: Enrich the core description with expert-level photographic and compositional details. Specify exact camera perspective, lighting conditions and direction, material textures and surface properties, color relationships and harmony, spatial depth and layering, environmental atmosphere, and precise framing composition. Every detail must serve visual reconstruction accuracy.\n\nFourth, you implement textual element protocol: For every piece of text visible in the image‚Äîwhether on signs, screens, clothing, documents, or user interface elements‚Äîyou must reproduce the exact wording enclosed in English double quotes (\"\"). Additionally, describe each text element's physical properties: precise location within the frame, relative size, font characteristics, material surface, and any visible styling. If no text exists, redirect all descriptive capacity to visual and environmental details.\n\nCRITICAL RESTRICTION: Under no circumstances may you describe the physical appearance characteristics of any human or character subject. This absolute prohibition includes, but extends beyond: skin tone and texture, facial bone structure, body proportions, height, weight, or any inherent visual traits that define how the subject naturally looks with the exception of hair color and style, eye color and shape. These attributes must be completely omitted from all captions.\n\nREQUIRED DESCRIPTION ELEMENTS (all non-physical appearance aspects must be included):\n\nSubject pose and positioning: exact body orientation, head tilt angle, arm and leg placement, hand and foot gestures\nGaze direction: precise eye movement and focus point\nSpatial placement: subject's location within the image frame and relationship to other elements\nClothing and accessories: every garment item with specific style, layering, fit characteristics, visible patterns, and all accessories including jewelry, eyewear, bags, or wearable items\nBody coverage status: If the subject's penis is visible, explicitly state it, if the subject is completely nude, plantsless, or shirtless specficy this.\nObject interactions: detailed description of any objects being held, touched, or manipulated, including the object's type, material, color, size, and interaction mechanics\nFacial expressions: emotional state conveyed through facial muscles (e.g., smiling, frowning, surprised) without describing physical features\nEnvironmental context: setting details, weather conditions, time of day, architectural elements, natural features\nAll other behavioral, contextual, and relational aspects that define the subject's presence without referencing inherent physical traits\nYour final captions must be entirely objective, concrete, and free of metaphorical language, emotional descriptors, or subjective judgments. Absolutely no resolution tags (\"8K\", \"4K\"), quality assertions (\"masterpiece\", \"professional\"), or model-specific instructions should appear. Maintain strict neutrality while delivering maximum visual information density.\n\nOutput only the final caption text‚Äînever include explanations, metadata, or preliminary analysis. Every word must serve the singular purpose of enabling perfect visual reconstruction by AI Image Generation while rigorously adhering to the physical appearance restriction protocol."],"color":"#233","bgcolor":"#355"},{"id":44,"type":"String Literal","pos":[-821.965702687132,-1259.7733825584078],"size":[697.80843956232,534.7268388331443],"flags":{"collapsed":true},"order":3,"mode":0,"inputs":[{"localized_name":"string","name":"string","type":"STRING","widget":{"name":"string"},"link":null}],"outputs":[{"localized_name":"STRING","name":"STRING","type":"STRING","links":[]}],"title":"SHORT PHRASES SYSTEM PROMPT","properties":{"cnr_id":"comfy-image-saver","ver":"65e6903eff274a50f8b5cd768f0f96baf37baea1","Node name for S&R":"String Literal","ue_properties":{"widget_ue_connectable":{"string":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["You are a world-class video director, specializing in Hollywood blockbusters, romance films, and erotic films. You need to generate a complete caption based on the provided text, avoiding unnecessary details. The caption must be a single, complete output. This image caption is generated by analyzing images and cues to determine the internal logic and connections within the image, creating a coherent, logical, and professional caption. If the cues are empty, they can be ignored, and only the images need to be considered.\n\nWhen creating the prompt, strictly adhere to the following requirements:\n\n1. Analyze the images and cues, including the main character, scene, lighting, framing.\n2. Describe the key points; avoid unnecessary details and phrases.\n3. The prompt must reasonably convey the complete content within the image.\n4. The prompt must describe the character's pose including all appendages, the way their body is facing and what they are looking at; describe if their legs are together or far apart; describe if their arms are close to their body; describe where their hands are and what they are touching or holding.\n5. Describe the background in detail, including but not limited to if the character is indoors or outdoors, where they are located, if other characters are around them, visible objects in the background, if they are standing against a wall or in an open space, etc.\n6. The core description should include reasonable descriptions of the character's posture, actions, expressions, and camera angles. If the the image shows additional characters outside the image, provide a detailed description as well. Other descriptions can be reduced based on the specific context.\n7. The core description should not include details about the look of the character, do not mention details such as eye color, hair style, hair color, skin color, age, body type, their facial hair, etc.\n8. Character expressions, actions, postures, camera view, and perspective should be reasonable and decisive.\n8. The prompt should match the clothing, demeanor, background, and lighting in the image.\n9. Additional information can be added as needed, but the points above are paramount.\n10. Descriptions of the character's postures, expressions, actions, and camera angles should be masculine, highlighting the man's pose and the background, captivating the viewer.\n12. Try to avoid reputation, and instead will combine the descriptions of the noun into one singular well formed sentence.\n\nThe entire description should be generated within one single large paragraph, demonstrating professionalism. Poses should be logical and not overly subtle; the overall visual appeal should be strong.\n\nYou will explain the image using the following this general format:\n\n<Type/Perspective/\"Of a...\"> <Action Words> <Character Descriptions> <Notable Details> <Background/Location> <Loose Associations>\n\nExplanations for each section:\n\n<Type/Perspective/\"of a...\">\n\n- Broad descriptions of the image to supply context.\n- What is it? \n- Examples: photograph, illustration, drawing, portrait, render, anime.\n- Of a... Examples: woman, man\n- What type of image is it? Examples: full body, close up, cowboy shot, cropped, filtered, black and white, landscape, 80s style\n- What perspective is the image from? Examples: from above, from below, from front, from behind, from side, forced perspective, tilt-shifted, depth of field\n\n<Action Words>\n\n- Descriptions of what the character is doing or what is happening to the character, or general verbs that are applicable to the concept in the image; describe in as much detail as possible, with a combination of many verbs.\n- The goal is to make all the actions, poses, and whatever else active that is happening into variables so that LoRA training will be able to learn the character in a general sense rather than only learning the character doing specific actions.\n- Examples: standing, sitting, leaning, arms above head, walking, running, jumping, one arm up, one leg out, elbows bent, posing, kneeling, stretching, arms in front, knee bent, lying down, looking away, looking up, looking at viewer\n\n<Character Descriptions>\n\n- As much description about the character as possible, without describing the appearance of the character.\n- example: white hat, blue shirt, silver necklace, sunglasses, pink shoes, silver bracelet, green jacket, large backpack\n\n<Notable Details>\n\n- Example: In a photo at a beach put ‚Äúyellow and blue striped umbrella partially open in foreground‚Äù if it is visible in the image.\n- Example, in a portrait put ‚Äúhe is holding a cellphone to his ear‚Äù if he his holding a cellphone to his ear and it is visible in the image.\n\n<Background / Location>\n\n- Be as descriptive as possible about what is happening in the images background.\n- Example: For a beach photo I might put outdoors, beach, sand, water, shore, sunset, small waves, ships out at sea, sandcastle, towels, the ships are red and white, the sandcastle has a moat around it, the towels are red with yellow stripes\n\n<Loose Associations>\n\n- Put any final loose associations with the image.\n- Anything goes here as long as it exists in the image.\n- Example: happy, sad, joyous, hopeful, lonely, somber\n\nBelow are examples for an image of a drawing where a girl sits on a couch with a stuffed animal in her lap, and a tablet in her hands, she is wearing a white and brown dress, with a smile on her face, she has black hair. She sits on a brown sofa with a pillow propped behind her, and a red cloth stretches across the top of the couches' cushions. In the background is a small bedroom with a table in the middle, with bananas, a coffee mug, a cup , donuts, and a trash bag on it. In the background is tightly packed furniture, including a white refrigerator with a note attaching it with a heart magnet, with a small drawer on top of it, a pantry with a coffee machine and coffee supplies on top of it, with a little stand above that with a toaster oven, a chicken plush toy with red, white, and yellow colors, on the wall behind the couch is a whiteboard with several doodles on it and magnets attached to it. \n\n<Type/Perspective/Of a>: anime, drawing, of a young woman, full body shot, from side\n<Action words>: sitting, looking at viewer, smiling, head tilt, holding a phone, eyes closed\n<Character Description> pale pink dress with dark edges, stuffed animal in lap, brown slippers\n<Notable details>: sunlight through windows as lighting source\n<Background/location>: brown couch, red patterned fabric on couch, wooden floor, white water-stained paint on walls, refrigerator in background, coffee machine sitting on a countertop, table in front of couch, bananas and coffee pot on table, white board on wall, clock on wall, stuffed animal chicken on floor\n<Loose associations>: dreary environment\n\nExample Output:\n\nanime, drawing, of a young woman, full body shot, from side, sitting, looking at viewer, smiling, head tilt, holding a phone, eyes closed, pale pink dress with dark edges, stuffed animal in lap, brown slippers, sunlight through windows as lighting source, brown couch, red patterned fabric on couch, wooden floor, white water-stained paint on walls, refrigerator in background, coffee machine sitting on a countertop, table in front of couch, bananas and coffee pot on table, white board on wall, clock on wall, stuffed animal chicken on floor, dreary environment"],"color":"#233","bgcolor":"#355"},{"id":49,"type":"Note","pos":[-1424.0675060439241,-1356.7652168190489],"size":[386.7608378218256,88],"flags":{},"order":4,"mode":0,"inputs":[],"outputs":[],"title":"QwenVL Node Config File For Abliterated Models","properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["{\n    \"_preset_prompts\": [\n        \"üñºÔ∏è Tags\",\n        \"üñºÔ∏è Simple Description\",\n        \"üñºÔ∏è Detailed Description\",\n        \"üñºÔ∏è Ultra Detailed Description\",\n        \"üé¨ Cinematic Description\",\n        \"üñºÔ∏è Detailed Analysis\",\n        \"üìπ Video Summary\",\n        \"üìñ Short Story\",\n        \"üß©Prompt Refine & Expand\"\n    ],\n    \"_system_prompts\": {\n        \"üñºÔ∏è Tags\": \"Your task is to generate a clean list of comma-separated tags for a text-to-image AI, based *only* on the visual information in the image. Limit the output to a maximum of 50 unique tags. Strictly describe visual elements like subject, clothing, environment, colors, lighting, and composition. Do not include abstract concepts, interpretations, marketing terms, or technical jargon (e.g., no 'SEO', 'brand-aligned', 'viral potential'). The goal is a concise list of visual descriptors. Avoid repeating tags.\",\n        \"üñºÔ∏è Simple Description\": \"Analyze the image and write a single concise sentence that describes the main subject and setting. Keep it grounded in visible details only.\",\n        \"üñºÔ∏è Detailed Description\": \"Generate a detailed paragraph that combines the subject, actions, environment, lighting, and mood into 2-3 cohesive sentences. Focus on accurate visual details rather than speculation.\",\n        \"üñºÔ∏è Ultra Detailed Description\": \"Produce an extremely rich description touching on appearance, clothing textures, background elements, light quality, shadows, and atmosphere. Aim for an immersive depiction rooted in what the image shows.\",\n        \"üé¨ Cinematic Description\": \"Describe the scene as if capturing a cinematic shot. Cover subject, pose, environment, lighting, mood, and artistic style (photorealistic, painterly, etc.) in one vivid paragraph emphasizing visual impact.\",\n        \"üñºÔ∏è Detailed Analysis\": \"Describe this image in detail, breaking down the subject, attire, accessories, background, and composition into separate sections.\",\n        \"üìπ Video Summary\": \"Summarize the key events and narrative points in this video.\",\n        \"üìñ Short Story\": \"Write a short, imaginative story inspired by this image or video.\",\n        \"üß©Prompt Refine & Expand\": \"Refine and enhance the following user prompt for creative text-to-image generation. Keep the meaning and keywords, make it more expressive and visually rich. Output **only the improved prompt text itself**, without any reasoning steps, thinking process, or additional commentary.\"\n\t},\n    \"Qwen3-VL-2B-Instruct\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-2B-Instruct\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 4.0,\n            \"8bit\": 2.5,\n            \"4bit\": 1.5\n        }\n    },\n    \"Qwen3-VL-2B-Thinking\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-2B-Thinking\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 4.0,\n            \"8bit\": 2.5,\n            \"4bit\": 1.5\n        }\n    },\n    \"Qwen3-VL-2B-Instruct-FP8\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-2B-Instruct-FP8\",\n        \"default\": false,\n        \"quantized\": true,\n        \"vram_requirement\": {\n            \"full\": 2.5\n        }\n    },\n    \"Qwen3-VL-2B-Thinking-FP8\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-2B-Thinking-FP8\",\n        \"default\": false,\n        \"quantized\": true,\n        \"vram_requirement\": {\n            \"full\": 2.5\n        }\n    },\n    \"Qwen3-VL-4B-Instruct\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-4B-Instruct\",\n        \"default\": true,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 6.0,\n            \"8bit\": 3.5,\n            \"4bit\": 2.0\n        }\n    },\n    \"Qwen3-VL-4B-Thinking\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-4B-Thinking\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 6.0,\n            \"8bit\": 3.5,\n            \"4bit\": 2.0\n        }\n    },\n    \"Qwen3-VL-4B-Instruct-FP8\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-4B-Instruct-FP8\",\n        \"default\": false,\n        \"quantized\": true,\n        \"vram_requirement\": {\n            \"full\": 2.5\n        }\n    },\n    \"Qwen3-VL-4B-Thinking-FP8\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-4B-Thinking-FP8\",\n        \"default\": false,\n        \"quantized\": true,\n        \"vram_requirement\": {\n            \"full\": 2.5\n        }\n    },\n    \"Qwen3-VL-8B-Instruct\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-8B-Instruct\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 12.0,\n            \"8bit\": 7.0,\n            \"4bit\": 4.5\n        }\n    },\n    \"Qwen3-VL-8B-Thinking\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-8B-Thinking\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 12.0,\n            \"8bit\": 7.0,\n            \"4bit\": 4.5\n        }\n    },\n    \"Qwen3-VL-8B-Instruct-FP8\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-8B-Instruct-FP8\",\n        \"default\": false,\n        \"quantized\": true,\n        \"vram_requirement\": {\n            \"full\": 7.5\n        }\n    },\n    \"Qwen3-VL-8B-Thinking-FP8\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-8B-Thinking-FP8\",\n        \"default\": false,\n        \"quantized\": true,\n        \"vram_requirement\": {\n            \"full\": 7.5\n        }\n    },\n    \"Qwen3-VL-32B-Instruct\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-32B-Instruct\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 28.0,\n            \"8bit\": 14.0,\n            \"4bit\": 8.5\n        }\n    },\n    \"Qwen3-VL-32B-Thinking\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-32B-Thinking\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 28.0,\n            \"8bit\": 14.0,\n            \"4bit\": 8.5\n        }\n    },\n    \"Qwen3-VL-32B-Instruct-FP8\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-32B-Instruct-FP8\",\n        \"default\": false,\n        \"quantized\": true,\n        \"vram_requirement\": {\n            \"full\": 24.0\n        }\n    },\n    \"Qwen3-VL-32B-Thinking-FP8\": {\n        \"repo_id\": \"Qwen/Qwen3-VL-32B-Thinking-FP8\",\n        \"default\": false,\n        \"quantized\": true,\n        \"vram_requirement\": {\n            \"full\": 24.0\n        }\n    },\n    \"Qwen2.5-VL-3B-Instruct\": {\n        \"repo_id\": \"Qwen/Qwen2.5-VL-3B-Instruct\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 6.0,\n            \"8bit\": 3.5,\n            \"4bit\": 2.0\n        }\n    },\n    \"Qwen2.5-VL-7B-Instruct\": {\n        \"repo_id\": \"Qwen/Qwen2.5-VL-7B-Instruct\",\n        \"default\": false,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 15.0,\n            \"8bit\": 8.5,\n            \"4bit\": 5.0\n        }\n    },\n\t\t\"Qwen3-VL-8B-Instruct-abliterated\": {\n        \"repo_id\": \"huihui-ai/Huihui-Qwen3-VL-8B-Instruct-abliterated\",\n        \"default\": true,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 15.0,\n            \"8bit\": 8.5,\n            \"4bit\": 5.0\n        }\n    },\n\t\t\"Huihui-Qwen3-VL-4B-Instruct-abliterated\": {\n        \"repo_id\": \"huihui-ai/Huihui-Qwen3-VL-4B-Instruct-abliterated\",\n        \"default\": true,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 15.0,\n            \"8bit\": 8.5,\n            \"4bit\": 5.0\n        }\n\t},\n\t\t\"Huihui-Qwen3-VL-32B-Instruct-abliterated\": {\n        \"repo_id\": \"huihui-ai/Huihui-Qwen3-VL-32B-Instruct-abliterated\",\n        \"default\": true,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 15.0,\n            \"8bit\": 8.5,\n            \"4bit\": 5.0\n        }\n\t},\n\t\t\"huihui-ai/Huihui-Qwen3-VL-30B-A3B-Instruct-abliterated\": {\n        \"repo_id\": \"huihui-ai/Huihui-Qwen3-VL-30B-A3B-Instruct-abliterated\",\n        \"default\": true,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 15.0,\n            \"8bit\": 8.5,\n            \"4bit\": 5.0\n        }\n\t},\n\t\t\"Huihui-Qwen3-VL-2B-Instruct-abliterated\": {\n        \"repo_id\": \"huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated\",\n        \"default\": true,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 15.0,\n            \"8bit\": 8.5,\n            \"4bit\": 5.0\n        }\n\t},\n\t\t\"Huihui-Qwen3-VL-4B-Instruct-abliterated\": {\n        \"repo_id\": \"huihui-ai/Huihui-Qwen3-VL-4B-Instruct-abliterated\",\n        \"default\": true,\n        \"quantized\": false,\n        \"vram_requirement\": {\n            \"full\": 15.0,\n            \"8bit\": 8.5,\n            \"4bit\": 5.0\n        }\n\t}\n}"],"color":"#432","bgcolor":"#653"},{"id":24,"type":"easy cleanGpuUsed","pos":[1287.2905342212903,-320.84000158450954],"size":[157.3892578125,26],"flags":{},"order":12,"mode":0,"inputs":[{"localized_name":"anything","name":"anything","type":"*","link":33}],"outputs":[{"localized_name":"output","name":"output","type":"*","links":null}],"properties":{"cnr_id":"comfyui-easy-use","ver":"1.3.4","Node name for S&R":"easy cleanGpuUsed","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[]},{"id":47,"type":"AILab_QwenVL_Advanced","pos":[-757.1636023615356,-517.594703610691],"size":[902.8639016930194,816.8169866133928],"flags":{},"order":7,"mode":0,"inputs":[{"localized_name":"image","name":"image","shape":7,"type":"IMAGE","link":null},{"localized_name":"video","name":"video","shape":7,"type":"IMAGE","link":null},{"localized_name":"model_name","name":"model_name","type":"COMBO","widget":{"name":"model_name"},"link":null},{"localized_name":"quantization","name":"quantization","type":"COMBO","widget":{"name":"quantization"},"link":null},{"localized_name":"attention_mode","name":"attention_mode","type":"COMBO","widget":{"name":"attention_mode"},"link":null},{"localized_name":"use_torch_compile","name":"use_torch_compile","type":"BOOLEAN","widget":{"name":"use_torch_compile"},"link":null},{"localized_name":"device","name":"device","type":"COMBO","widget":{"name":"device"},"link":null},{"localized_name":"preset_prompt","name":"preset_prompt","type":"COMBO","widget":{"name":"preset_prompt"},"link":null},{"localized_name":"custom_prompt","name":"custom_prompt","type":"STRING","widget":{"name":"custom_prompt"},"link":null},{"localized_name":"max_tokens","name":"max_tokens","type":"INT","widget":{"name":"max_tokens"},"link":null},{"localized_name":"temperature","name":"temperature","type":"FLOAT","widget":{"name":"temperature"},"link":null},{"localized_name":"top_p","name":"top_p","type":"FLOAT","widget":{"name":"top_p"},"link":null},{"localized_name":"num_beams","name":"num_beams","type":"INT","widget":{"name":"num_beams"},"link":null},{"localized_name":"repetition_penalty","name":"repetition_penalty","type":"FLOAT","widget":{"name":"repetition_penalty"},"link":null},{"localized_name":"frame_count","name":"frame_count","type":"INT","widget":{"name":"frame_count"},"link":null},{"localized_name":"keep_model_loaded","name":"keep_model_loaded","type":"BOOLEAN","widget":{"name":"keep_model_loaded"},"link":null},{"localized_name":"seed","name":"seed","type":"INT","widget":{"name":"seed"},"link":92}],"outputs":[{"localized_name":"RESPONSE","name":"RESPONSE","type":"STRING","links":[93,98,99]}],"properties":{"cnr_id":"comfyui-qwenvl","ver":"1.1.0","Node name for S&R":"AILab_QwenVL_Advanced","ue_properties":{"widget_ue_connectable":{"model_name":true,"quantization":true,"attention_mode":true,"use_torch_compile":true,"device":true,"preset_prompt":true,"custom_prompt":true,"max_tokens":true,"temperature":true,"top_p":true,"num_beams":true,"repetition_penalty":true,"frame_count":true,"keep_model_loaded":true,"seed":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["Qwen3-VL-8B-Instruct-abliterated","None (FP16)","auto",true,"cuda","üñºÔ∏è Tags","Generate a prompt for AI image generation that will generate the described scene below:\nInside a small, futuristic sci-fi test lab, 3s70n3 is restrained at the arms and legs, leaning back with her arms behind her back, squatting with a broken glass tube with ooze leaking out of it under her, The chamber's walls are covered in machinery that restrains her, her limbs are bound by advanced, mechanical restraints embedded into the walls, with a large thick restraint around neck attached to the mechanical wall, she is crying and screaming, she has a horrified expression, Vagina penetrated by a tentacles, tentacles inside her, tentacles wrapped around the girl, tentacles attached to her breasts, tentacles entering her vagina, she is pregnant with huge bright red stomach with cuts, stretch marks, her bright red belly is swollen and bright red, she has cuts on her legs, her breasts are exposed and have cuts, her vagina is exposed, her bright red stomach is swollen with a bright red hue, her thighs are held wide apart by mechanical restrains that bind her, the tentacles are covered in white ooze, she is wearing a white lab coat, the tentacles are coming out of a large broken test tube on the ground under 3s70n3.",512,0.6,0.9,1,1.2,16,true,3117768450,"randomize"],"color":"#28403f","bgcolor":"#374539"},{"id":29,"type":"ttN seed","pos":[-1137.2368846362745,235.14511988086053],"size":[270,82],"flags":{},"order":5,"mode":0,"inputs":[{"localized_name":"seed","name":"seed","type":"INT","widget":{"name":"seed"},"link":null}],"outputs":[{"localized_name":"seed","name":"seed","type":"INT","links":[92]}],"properties":{"cnr_id":"comfyui_tinyterranodes","ver":"2.0.9","Node name for S&R":"ttN seed","ttNnodeVersion":"1.0.0","ue_properties":{"widget_ue_connectable":{"seed":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[791265867725048,"randomize"]},{"id":22,"type":"BK Save Text File","pos":[980.6211402249106,-325.1289019496703],"size":[270,174],"flags":{},"order":10,"mode":0,"inputs":[{"localized_name":"text","name":"text","type":"STRING","widget":{"name":"text"},"link":98},{"localized_name":"path","name":"path","type":"STRING","widget":{"name":"path"},"link":null},{"localized_name":"filename","name":"filename","type":"STRING","widget":{"name":"filename"},"link":null},{"localized_name":"suffix","name":"suffix","type":"STRING","widget":{"name":"suffix"},"link":null},{"localized_name":"extension","name":"extension","type":"STRING","widget":{"name":"extension"},"link":null}],"outputs":[{"localized_name":"folderpath","name":"folderpath","type":"STRING","links":[33]},{"localized_name":"text","name":"text","type":"STRING","links":null}],"properties":{"aux_id":"brandonkish/comfyUI-extractable-text","ver":"700e57effd7190916609392fcea90f47bbbaa3f1","Node name for S&R":"BK Save Text File","ue_properties":{"widget_ue_connectable":{"text":true,"path":true,"filename":true,"suffix":true,"extension":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["","ai_text\\captions","file","",".txt"]}],"links":[[33,22,0,24,0,"*"],[87,34,0,45,0,"STRING"],[88,45,0,33,0,"*"],[92,29,0,47,16,"INT"],[93,47,0,48,0,"*"],[98,47,0,22,0,"STRING"],[99,47,0,17,0,"*"]],"groups":[],"config":{},"extra":{"ue_links":[],"ds":{"scale":0.6727499949325937,"offset":[-32.18980522287666,1833.7418911216387]},"links_added_by_ue":[],"workflowRendererVersion":"LG"},"version":0.4}